{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a basic working example of sentiment analysis\n",
    "# I am using TF GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# checking GPU\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# print(\"Num GPUs Available: \", len(physical_devices))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from glob import glob\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check tf version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.9\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all the input data files, tab seperated values\n",
    "data_txt = glob('/tf/deep_learning/sentiment_analysis/data/*.txt')\n",
    "data_tsv = glob('/tf/deep_learning/sentiment_analysis/data/*.tsv')\n",
    "model_file = '/tf/deep_learning/sentiment_analysis/lib/model'\n",
    "header_list = [\"comments\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # read all the data using windows encoding and python engine. Else it will give error for windows files\n",
    "# # l = [pd.read_csv(f, sep='\\t', names=header_list, encoding = \"ISO-8859-1\", engine='python') for f in data_txt]\n",
    "# l = [pd.read_csv(f, sep='\\t', names=header_list) for f in data_txt]\n",
    "# data_txt = pd.concat(l, axis=0)\n",
    "# print('total length of the training data_txt %s'%(len(data_txt)))\n",
    "\n",
    "# # read all the data using windows encoding and python engine. Else it will give error for windows files\n",
    "# # l = [pd.read_csv(f, sep='|', names=header_list, encoding = \"ISO-8859-1\", engine='python') for f in data_tsv]\n",
    "# l = [pd.read_csv(f, sep='|', names=header_list) for f in data_tsv]\n",
    "# data_tsv = pd.concat(l, axis=0)\n",
    "# print('total length of the training data_tsv %s'%(len(data_tsv)))\n",
    "# # total data\n",
    "# frames = [data_txt, data_tsv]\n",
    "# data = pd.concat(frames)\n",
    "# print('total length of the training data %s'%(len(data)))\n",
    "\n",
    "# # drop the base data and free the memory\n",
    "# del [[l,data_txt, data_tsv]]\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great for the jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the mic is great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52995</th>\n",
       "      <td>loved this showsmart acting smart dialog great...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52996</th>\n",
       "      <td>for long time i have not seen such a good fant...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52997</th>\n",
       "      <td>andy goldsworthy is a taoist master of the fir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52998</th>\n",
       "      <td>vonneguts words are best experienced on paper ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52999</th>\n",
       "      <td>i missed the entire season of the show and sta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52998 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comments  sentiment\n",
       "0      so there is no way for me to plug it in here i...          0\n",
       "1                              good case excellent value          1\n",
       "2                                  great for the jawbone          1\n",
       "3      tied to charger for conversations lasting more...          0\n",
       "4                                       the mic is great          1\n",
       "...                                                  ...        ...\n",
       "52995  loved this showsmart acting smart dialog great...          1\n",
       "52996  for long time i have not seen such a good fant...          1\n",
       "52997  andy goldsworthy is a taoist master of the fir...          1\n",
       "52998  vonneguts words are best experienced on paper ...          1\n",
       "52999  i missed the entire season of the show and sta...          1\n",
       "\n",
       "[52998 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new data\n",
    "data = pd.read_csv('/tf/deep_learning/sentiment_analysis/data/sentiment_all_clean_multi.csv')\n",
    "data = data[['comments', 'sentiment']].dropna()\n",
    "data = (data[data['comments'] != 'oct'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           comments\n",
       "sentiment          \n",
       "0             26500\n",
       "1             26498"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets do data explore\n",
    "# how many neg/pos\n",
    "# looks like evenly split\n",
    "data.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52998, 2)\n",
      "comments     object\n",
      "sentiment     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13309 6\n"
     ]
    }
   ],
   "source": [
    "# check the review length\n",
    "max_len = data['comments'].astype('str').map(len).max()\n",
    "min_len = data['comments'].astype('str').map(len).min()\n",
    "print(max_len, min_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>good case</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>it works</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>delicious</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>horrible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>so bad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>see it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>hated it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       comments  sentiment\n",
       "827   good case          1\n",
       "857    it works          1\n",
       "877   excellent          1\n",
       "1165  delicious          1\n",
       "2155  horrible           0\n",
       "2162     awful           0\n",
       "2198    so bad           0\n",
       "2493    see it           1\n",
       "2907  hated it           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['comments'].astype('str').map(len) < 10]\n",
    "# need data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all NaN values\n",
    "data.dropna(subset = [\"comments\"], inplace=True)\n",
    "# drop duplicates\n",
    "data.drop_duplicates(subset=None, keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.plotting.backend = \"plotly\"\n",
    "# data[['review_len']].plot(title=\"Pandas Backend Example\", template=\"simple_white\",\n",
    "#               labels=dict(index=\"time\", value=\"money\", variable=\"option\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42036,)\n",
      "(42036,)\n",
      "(7882,)\n",
      "(7882,)\n",
      "(2628,)\n",
      "(2628,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get training data, use balanced split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"comments\"], data[\"sentiment\"], test_size=0.20, random_state=42, stratify=data['sentiment'])\n",
    "# get test and validation data, use balanced split\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.25, random_state=42, stratify=y_test)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "# drop the base data and free the memory\n",
    "# del [[l,data]]\n",
    "del [[data]]\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    21093\n",
      "0    20943\n",
      "Name: sentiment, dtype: int64\n",
      "1    3955\n",
      "0    3927\n",
      "Name: sentiment, dtype: int64\n",
      "1    1319\n",
      "0    1309\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check if the data is balanced\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding using TF lib\n",
    "vocab_size = 10000\n",
    "# max_review_length = 200\n",
    "max_review_length = 250\n",
    "oov_tok = \"<OOV>\"\n",
    "embedding_dim = 16\n",
    "# embedding_dim = 32\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the tokenizer, for the API\n",
    "tokenizer_json = tokenizer.to_json()\n",
    "with open(model_file+'/tokenizer.json', 'w', encoding='utf-8') as f:\n",
    "    f.write(json.dumps(tokenizer_json, ensure_ascii=False))\n",
    "word_index = tokenizer.word_index\n",
    "# training data\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "train_padding = pad_sequences(train_sequences, truncating='post', padding='post', maxlen=max_review_length)\n",
    "# test data\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "test_padding = pad_sequences(test_sequences, truncating='post', padding='post', maxlen=max_review_length)\n",
    "# validation data\n",
    "validation_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "validation_padding = pad_sequences(validation_sequences, truncating='post', padding='post', maxlen=max_review_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need this block to get it to work with TensorFlow 2.x, converting to NP array\n",
    "# training\n",
    "training_padded = np.array(train_padding)\n",
    "training_labels = np.array(y_train)\n",
    "# testing\n",
    "testing_padded = np.array(test_padding)\n",
    "testing_labels = np.array(y_test)\n",
    "# validation\n",
    "validation_padded = np.array(validation_padding)\n",
    "validation_labels = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 996,   51,    9, ...,    0,    0,    0],\n",
       "       [  11,   14,   95, ...,    0,    0,    0],\n",
       "       [   1,  299,  176, ..., 1026,    6, 2132],\n",
       "       ...,\n",
       "       [6664,    1,    1, ...,    0,    0,    0],\n",
       "       [  11,   18, 1507, ...,    0,    0,    0],\n",
       "       [   9,   91,  199, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the data\n",
    "training_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "4204/4204 - 23s - loss: 0.3913 - accuracy: 0.8268 - val_loss: 0.3062 - val_accuracy: 0.8756\n",
      "Epoch 2/45\n",
      "4204/4204 - 24s - loss: 0.2594 - accuracy: 0.8942 - val_loss: 0.3042 - val_accuracy: 0.8687\n",
      "Epoch 3/45\n",
      "4204/4204 - 25s - loss: 0.2283 - accuracy: 0.9089 - val_loss: 0.3129 - val_accuracy: 0.8687\n",
      "Epoch 4/45\n",
      "4204/4204 - 23s - loss: 0.2086 - accuracy: 0.9188 - val_loss: 0.3189 - val_accuracy: 0.8706\n",
      "Epoch 5/45\n",
      "4204/4204 - 23s - loss: 0.1951 - accuracy: 0.9256 - val_loss: 0.3396 - val_accuracy: 0.8676\n",
      "Epoch 6/45\n",
      "4204/4204 - 22s - loss: 0.1834 - accuracy: 0.9313 - val_loss: 0.3414 - val_accuracy: 0.8664\n",
      "Epoch 7/45\n",
      "4204/4204 - 23s - loss: 0.1750 - accuracy: 0.9354 - val_loss: 0.3747 - val_accuracy: 0.8588\n",
      "Epoch 8/45\n",
      "4204/4204 - 23s - loss: 0.1675 - accuracy: 0.9392 - val_loss: 0.3760 - val_accuracy: 0.8596\n",
      "Epoch 9/45\n",
      "4204/4204 - 23s - loss: 0.1612 - accuracy: 0.9412 - val_loss: 0.3939 - val_accuracy: 0.8543\n",
      "Epoch 10/45\n",
      "4204/4204 - 23s - loss: 0.1527 - accuracy: 0.9437 - val_loss: 0.4038 - val_accuracy: 0.8584\n",
      "Epoch 11/45\n",
      "4204/4204 - 23s - loss: 0.1429 - accuracy: 0.9472 - val_loss: 0.4418 - val_accuracy: 0.8584\n",
      "Epoch 12/45\n",
      "4204/4204 - 23s - loss: 0.1339 - accuracy: 0.9495 - val_loss: 0.4578 - val_accuracy: 0.8546\n",
      "Epoch 13/45\n",
      "4204/4204 - 23s - loss: 0.1226 - accuracy: 0.9530 - val_loss: 0.4715 - val_accuracy: 0.8554\n",
      "Epoch 14/45\n",
      "4204/4204 - 23s - loss: 0.1108 - accuracy: 0.9576 - val_loss: 0.5113 - val_accuracy: 0.8569\n",
      "Epoch 15/45\n",
      "4204/4204 - 23s - loss: 0.0990 - accuracy: 0.9616 - val_loss: 0.5411 - val_accuracy: 0.8516\n",
      "Epoch 16/45\n",
      "4204/4204 - 23s - loss: 0.0887 - accuracy: 0.9660 - val_loss: 0.6429 - val_accuracy: 0.8478\n",
      "Epoch 17/45\n",
      "4204/4204 - 23s - loss: 0.0789 - accuracy: 0.9701 - val_loss: 0.6621 - val_accuracy: 0.8482\n",
      "Epoch 18/45\n",
      "4204/4204 - 23s - loss: 0.0700 - accuracy: 0.9741 - val_loss: 0.7106 - val_accuracy: 0.8440\n",
      "Epoch 19/45\n",
      "4204/4204 - 23s - loss: 0.0618 - accuracy: 0.9767 - val_loss: 0.7766 - val_accuracy: 0.8501\n",
      "Epoch 20/45\n",
      "4204/4204 - 23s - loss: 0.0556 - accuracy: 0.9795 - val_loss: 0.8331 - val_accuracy: 0.8474\n",
      "Epoch 21/45\n",
      "4204/4204 - 23s - loss: 0.0504 - accuracy: 0.9814 - val_loss: 0.8771 - val_accuracy: 0.8451\n",
      "Epoch 22/45\n",
      "4204/4204 - 23s - loss: 0.0453 - accuracy: 0.9824 - val_loss: 0.9617 - val_accuracy: 0.8493\n",
      "Epoch 23/45\n",
      "4204/4204 - 23s - loss: 0.0409 - accuracy: 0.9848 - val_loss: 1.0310 - val_accuracy: 0.8501\n",
      "Epoch 24/45\n",
      "4204/4204 - 23s - loss: 0.0383 - accuracy: 0.9851 - val_loss: 1.1300 - val_accuracy: 0.8447\n",
      "Epoch 25/45\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-8382c20f489c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s/sentiment_dnn.h5\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # creating simple model, without early stopping\n",
    "# # increse the batch size if you need to run it faster. optimal batch size is between 1 to 32\n",
    "# batch_size=10\n",
    "# num_epochs = 45\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "#     tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#     tf.keras.layers.Dense(24, activation='relu'),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "#     ])\n",
    "# #Compile with binary_crossentropy as it's a binary predictions with adam optimizer, not setting the learning rate\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=2)\n",
    "# #save the model\n",
    "# model.save(\"%s/sentiment_dnn.h5\" %model_file)\n",
    "# print(model.summary())\n",
    "\n",
    "# # Final evaluation of the model\n",
    "# score, acc = model.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "# print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating checkpoint\n",
    "filepath=(model_file+\"\\weights.best.hdf5\")\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74239, saving model to /tf/deep_learning/sentiment_analysis/lib/model\\weights.best.hdf5\n",
      "4204/4204 - 23s - loss: 0.4372 - accuracy: 0.8115 - val_loss: 0.5170 - val_accuracy: 0.7424\n",
      "Epoch 2/25\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74239 to 0.80213, saving model to /tf/deep_learning/sentiment_analysis/lib/model\\weights.best.hdf5\n",
      "4204/4204 - 23s - loss: 0.3362 - accuracy: 0.8682 - val_loss: 0.6781 - val_accuracy: 0.8021\n",
      "Epoch 3/25\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.80213 to 0.84285, saving model to /tf/deep_learning/sentiment_analysis/lib/model\\weights.best.hdf5\n",
      "4204/4204 - 23s - loss: 0.3226 - accuracy: 0.8779 - val_loss: 0.3969 - val_accuracy: 0.8428\n",
      "Epoch 4/25\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84285 to 0.85008, saving model to /tf/deep_learning/sentiment_analysis/lib/model\\weights.best.hdf5\n",
      "4204/4204 - 23s - loss: 0.3007 - accuracy: 0.8952 - val_loss: 0.5304 - val_accuracy: 0.8501\n",
      "Epoch 5/25\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.85008\n",
      "4204/4204 - 23s - loss: 0.3070 - accuracy: 0.8877 - val_loss: 0.5011 - val_accuracy: 0.8501\n",
      "Epoch 6/25\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.85008 to 0.86035, saving model to /tf/deep_learning/sentiment_analysis/lib/model\\weights.best.hdf5\n",
      "4204/4204 - 23s - loss: 0.2764 - accuracy: 0.9057 - val_loss: 0.7211 - val_accuracy: 0.8604\n",
      "Epoch 7/25\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.2914 - accuracy: 0.9044 - val_loss: 0.6898 - val_accuracy: 0.5068\n",
      "Epoch 8/25\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.2865 - accuracy: 0.8969 - val_loss: 0.5273 - val_accuracy: 0.8588\n",
      "Epoch 9/25\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3537 - accuracy: 0.8887 - val_loss: 0.6601 - val_accuracy: 0.8501\n",
      "Epoch 10/25\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 25s - loss: 0.2690 - accuracy: 0.9139 - val_loss: 0.5679 - val_accuracy: 0.8459\n",
      "Epoch 11/25\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 24s - loss: 0.2729 - accuracy: 0.9107 - val_loss: 0.4353 - val_accuracy: 0.8413\n",
      "Epoch 12/25\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.2509 - accuracy: 0.9185 - val_loss: 0.8138 - val_accuracy: 0.8539\n",
      "Epoch 13/25\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3043 - accuracy: 0.9031 - val_loss: 2.3643 - val_accuracy: 0.8276\n",
      "Epoch 14/25\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3222 - accuracy: 0.9013 - val_loss: 1.5502 - val_accuracy: 0.8493\n",
      "Epoch 15/25\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.2952 - accuracy: 0.8976 - val_loss: 0.9547 - val_accuracy: 0.8360\n",
      "Epoch 16/25\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3558 - accuracy: 0.8651 - val_loss: 1.2019 - val_accuracy: 0.8368\n",
      "Epoch 17/25\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.2881 - accuracy: 0.9043 - val_loss: 0.9761 - val_accuracy: 0.8489\n",
      "Epoch 18/25\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3956 - accuracy: 0.8074 - val_loss: 0.5675 - val_accuracy: 0.8387\n",
      "Epoch 19/25\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.4069 - accuracy: 0.8457 - val_loss: 1.4234 - val_accuracy: 0.7945\n",
      "Epoch 20/25\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3515 - accuracy: 0.8718 - val_loss: 1.4108 - val_accuracy: 0.7530\n",
      "Epoch 21/25\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.4148 - accuracy: 0.8692 - val_loss: 0.9995 - val_accuracy: 0.8356\n",
      "Epoch 22/25\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3621 - accuracy: 0.8649 - val_loss: 2.3327 - val_accuracy: 0.7683\n",
      "Epoch 23/25\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3930 - accuracy: 0.8349 - val_loss: 1.5203 - val_accuracy: 0.8417\n",
      "Epoch 24/25\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3888 - accuracy: 0.8762 - val_loss: 1.8550 - val_accuracy: 0.8272\n",
      "Epoch 25/25\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86035\n",
      "4204/4204 - 23s - loss: 0.3611 - accuracy: 0.8624 - val_loss: 0.8755 - val_accuracy: 0.8269\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 240)               4080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 241       \n",
      "=================================================================\n",
      "Total params: 164,321\n",
      "Trainable params: 164,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "789/789 [==============================] - 2s 3ms/step - loss: 0.9230 - accuracy: 0.8329\n",
      "0.923002302646637 0.832910418510437\n"
     ]
    }
   ],
   "source": [
    "# creating simple model 240-1,0.1\n",
    "batch_size=10\n",
    "num_epochs = 25\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(240, activation='relu'),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "#     tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=callbacks_list, verbose=2)\n",
    "#save the model\n",
    "model.save(filepath)\n",
    "print(model.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85008, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_dnn_n240_lr0001.h5\n",
      "4204/4204 - 28s - loss: 0.5535 - accuracy: 0.7562 - val_loss: 0.3833 - val_accuracy: 0.8501\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85008 to 0.86758, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_dnn_n240_lr0001.h5\n",
      "4204/4204 - 29s - loss: 0.3799 - accuracy: 0.8458 - val_loss: 0.3419 - val_accuracy: 0.8676\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.86758\n",
      "4204/4204 - 29s - loss: 0.3462 - accuracy: 0.8610 - val_loss: 0.3345 - val_accuracy: 0.8619\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.86758\n",
      "4204/4204 - 30s - loss: 0.3194 - accuracy: 0.8739 - val_loss: 0.3382 - val_accuracy: 0.8554\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.86758 to 0.87519, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_dnn_n240_lr0001.h5\n",
      "4204/4204 - 29s - loss: 0.3082 - accuracy: 0.8763 - val_loss: 0.3262 - val_accuracy: 0.8752\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.87519 to 0.87938, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_dnn_n240_lr0001.h5\n",
      "4204/4204 - 27s - loss: 0.2998 - accuracy: 0.8820 - val_loss: 0.3192 - val_accuracy: 0.8794\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 26s - loss: 0.2894 - accuracy: 0.8863 - val_loss: 0.3461 - val_accuracy: 0.8638\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 28s - loss: 0.2832 - accuracy: 0.8880 - val_loss: 0.3281 - val_accuracy: 0.8721\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 29s - loss: 0.2766 - accuracy: 0.8916 - val_loss: 0.3841 - val_accuracy: 0.8489\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 29s - loss: 0.2700 - accuracy: 0.8967 - val_loss: 0.3372 - val_accuracy: 0.8661\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 33s - loss: 0.2629 - accuracy: 0.8988 - val_loss: 0.3518 - val_accuracy: 0.8562\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 33s - loss: 0.2611 - accuracy: 0.8982 - val_loss: 0.3737 - val_accuracy: 0.8421\n",
      "Epoch 13/50\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 33s - loss: 0.2566 - accuracy: 0.8996 - val_loss: 0.3452 - val_accuracy: 0.8634\n",
      "Epoch 14/50\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 34s - loss: 0.2593 - accuracy: 0.8998 - val_loss: 0.3506 - val_accuracy: 0.8600\n",
      "Epoch 15/50\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 32s - loss: 0.2500 - accuracy: 0.9044 - val_loss: 0.4119 - val_accuracy: 0.8474\n",
      "Epoch 16/50\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.87938\n",
      "4204/4204 - 34s - loss: 0.2496 - accuracy: 0.9040 - val_loss: 0.3601 - val_accuracy: 0.8626\n",
      "Model: \"sequential_79\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_80 (Embedding)     (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_80  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 900)               15300     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 900)               3600      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 1)                 901       \n",
      "=================================================================\n",
      "Total params: 179,801\n",
      "Trainable params: 178,001\n",
      "Non-trainable params: 1,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "789/789 [==============================] - 3s 3ms/step - loss: 0.3564 - accuracy: 0.8649\n",
      "0.3564104437828064 0.8648819923400879\n"
     ]
    }
   ],
   "source": [
    "# creating simple model 240-1,0.0001\n",
    "\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'sentiment_dnn_n240_lr0001.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "batch_size=10\n",
    "num_epochs = 50\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#     tf.keras.layers.Dense(240, activation='relu'),\n",
    "    tf.keras.layers.Dense(900, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.BatchNormalization(axis=1),\n",
    "    tf.keras.layers.Dropout(0.50),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "#     tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=callbacks_list, verbose=2)\n",
    "model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, shuffle= True, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "#save the model\n",
    "# model.save(filepath)\n",
    "model.save(\"%s/sentiment_dnn_n240_lr0001.h5\" %model_file)\n",
    "print(model.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789/789 - 2s - loss: 0.3564 - accuracy: 0.8649\n",
      "[0.3564104437828064, 0.8648819923400879]\n",
      "accuracy: 86.49%\n",
      "Generate predictions for 10 samples\n",
      "predictions shape: (7882, 1)\n"
     ]
    }
   ],
   "source": [
    "# 1 -> positive\n",
    "# 0 -> negative\n",
    "def sentiment(score):\n",
    "    new_score=[None] * (len(score))\n",
    "    for position in range(len(score)):\n",
    "        if score[position] >= 0.50:\n",
    "            new_score[position]=1\n",
    "        else:\n",
    "            new_score[position]=0\n",
    "    return(new_score)\n",
    "# load the best model and check the accuracy\n",
    "# load weights, not the model\n",
    "# we can save the model and use it, which is a better solutions\n",
    "# new_model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "#     tf.keras.layers.GlobalAveragePooling1D(),\n",
    "#     tf.keras.layers.Dense(700, activation='relu'),\n",
    "#     tf.keras.layers.BatchNormalization(axis=1),\n",
    "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "# new_model.load_weights(\"%s/sentiment_dnn_n240_lr0001.h5\" %model_file)\n",
    "# new_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# load the model\n",
    "\n",
    "new_model = tf.keras.models.load_model(\"%s/sentiment_dnn_n240_lr0001.h5\" %model_file)\n",
    "scores = new_model.evaluate(testing_padded, testing_labels, batch_size=batch_size, verbose=2)\n",
    "print(scores)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 10 samples\")\n",
    "predictions = model.predict(testing_padded)\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# print(X_test[:3])\n",
    "# print(type(np.array(sentiment(predictions))))\n",
    "# print(type(testing_labels[:10]))\n",
    "# print(np.array(sentiment(predictions)))\n",
    "# print(testing_labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[3368  559]\n",
      " [ 506 3449]]\n",
      "Confusion matrix : \n",
      " [[3368  559]\n",
      " [ 506 3449]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      3927\n",
      "           1       0.86      0.87      0.87      3955\n",
      "\n",
      "    accuracy                           0.86      7882\n",
      "   macro avg       0.86      0.86      0.86      7882\n",
      "weighted avg       0.86      0.86      0.86      7882\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_true=testing_labels, y_pred=np.array(sentiment(predictions)),labels=[0,1])\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cm_plot_labels = ['negative','positive']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
    "matrix = confusion_matrix(testing_labels,np.array(sentiment(predictions)),labels=[0,1])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "matrix = classification_report(testing_labels,np.array(sentiment(predictions)),labels=[0,1])\n",
    "print('Classification report : \\n',matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_91\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_89 (Embedding)     (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 243, 32)           4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 243, 32)           972       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 121, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 240)               929520    \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 1)                 241       \n",
      "=================================================================\n",
      "Total params: 1,094,861\n",
      "Trainable params: 1,094,375\n",
      "Non-trainable params: 486\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.87519, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_cnn_test.h5\n",
      "4204/4204 - 32s - loss: 0.3868 - accuracy: 0.8379 - val_loss: 0.3061 - val_accuracy: 0.8752\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.87519 to 0.87557, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_cnn_test.h5\n",
      "4204/4204 - 32s - loss: 0.2390 - accuracy: 0.9089 - val_loss: 0.3027 - val_accuracy: 0.8756\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.1777 - accuracy: 0.9367 - val_loss: 0.3130 - val_accuracy: 0.8756\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.1201 - accuracy: 0.9603 - val_loss: 0.4240 - val_accuracy: 0.8748\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0852 - accuracy: 0.9729 - val_loss: 0.4670 - val_accuracy: 0.8645\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0667 - accuracy: 0.9806 - val_loss: 0.5548 - val_accuracy: 0.8725\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0573 - accuracy: 0.9841 - val_loss: 0.6608 - val_accuracy: 0.8702\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0519 - accuracy: 0.9856 - val_loss: 0.7575 - val_accuracy: 0.8725\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0479 - accuracy: 0.9878 - val_loss: 0.8336 - val_accuracy: 0.8649\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0458 - accuracy: 0.9888 - val_loss: 1.0636 - val_accuracy: 0.8524\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0430 - accuracy: 0.9898 - val_loss: 0.9469 - val_accuracy: 0.8584\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87557\n",
      "4204/4204 - 32s - loss: 0.0434 - accuracy: 0.9900 - val_loss: 1.3232 - val_accuracy: 0.8447\n",
      "247/247 - 1s - loss: 1.4289 - accuracy: 0.8357\n",
      "[1.4288756847381592, 0.835701584815979]\n",
      "accuracy: 83.57%\n"
     ]
    }
   ],
   "source": [
    "# try CNN\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'sentiment_cnn_test.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "batch_size=10\n",
    "num_epochs = 50\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=8, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(tf.keras.layers.BatchNormalization(axis=1))\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(240, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "print(model.summary())\n",
    "# compile network\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, shuffle= True, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "# evaluate\n",
    "scores = model.evaluate(testing_padded, testing_labels, verbose=2)\n",
    "print(scores)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_12 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 250, 16]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-c4c0e2efa655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_review_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n\u001b[0;32m---> 12\u001b[0;31m                  activation ='relu'))\n\u001b[0m\u001b[1;32m     13\u001b[0m model.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n\u001b[1;32m     14\u001b[0m                  activation ='relu'))\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 886\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    887\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[1;32m    888\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    178\u001b[0m                          \u001b[0;34m'expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                          str(x.shape.as_list()))\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_12 is incompatible with the layer: expected ndim=4, found ndim=3. Full shape received: [None, 250, 16]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best DNN model and early stopping\n",
    "# saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'sentiment_dnn_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'sentiment_dnn_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85807, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_dnn_best.h5\n",
      "42036/42036 - 206s - loss: 0.5896 - accuracy: 0.8026 - val_loss: 0.5683 - val_accuracy: 0.8581\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85807 to 0.86149, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_dnn_best.h5\n",
      "42036/42036 - 194s - loss: 0.5625 - accuracy: 0.8684 - val_loss: 0.5686 - val_accuracy: 0.8615\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 193s - loss: 0.5578 - accuracy: 0.8797 - val_loss: 0.5713 - val_accuracy: 0.8413\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 193s - loss: 0.5549 - accuracy: 0.8855 - val_loss: 0.5695 - val_accuracy: 0.8512\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 194s - loss: 0.5527 - accuracy: 0.8901 - val_loss: 0.5717 - val_accuracy: 0.8470\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 183s - loss: 0.5504 - accuracy: 0.8955 - val_loss: 0.5735 - val_accuracy: 0.8463\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 193s - loss: 0.5489 - accuracy: 0.8995 - val_loss: 0.5727 - val_accuracy: 0.8447\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 193s - loss: 0.5474 - accuracy: 0.9025 - val_loss: 0.5779 - val_accuracy: 0.8269\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 182s - loss: 0.5452 - accuracy: 0.9069 - val_loss: 0.5720 - val_accuracy: 0.8611\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 182s - loss: 0.5445 - accuracy: 0.9086 - val_loss: 0.5705 - val_accuracy: 0.8573\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.86149\n",
      "42036/42036 - 184s - loss: 0.5436 - accuracy: 0.9108 - val_loss: 0.5743 - val_accuracy: 0.8562\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_16  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7882/7882 [==============================] - 18s 2ms/step - loss: 0.5753 - accuracy: 0.8555\n",
      "0.5752737522125244 0.8554935455322266\n"
     ]
    }
   ],
   "source": [
    "# approach 2(85%)\n",
    "# creating simple model\n",
    "batch_size=1\n",
    "num_epochs = 50\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model_2.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "# history = model_2.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=2)\n",
    "#save the model\n",
    "model_2.save(\"%s/model_2sentiment_dnn.h5\" %model_file)\n",
    "print(model_2.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model_2.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85312, saving model to /tf/deep_learning/sentiment_analysis/lib/modelmodel_3_sentiment_dnn.h5\n",
      "42036/42036 - 182s - loss: 0.5890 - accuracy: 0.8071 - val_loss: 0.5723 - val_accuracy: 0.8531\n",
      "Epoch 2/500\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85312 to 0.86301, saving model to /tf/deep_learning/sentiment_analysis/lib/modelmodel_3_sentiment_dnn.h5\n",
      "42036/42036 - 181s - loss: 0.5613 - accuracy: 0.8715 - val_loss: 0.5747 - val_accuracy: 0.8630\n",
      "Epoch 3/500\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5564 - accuracy: 0.8806 - val_loss: 0.5689 - val_accuracy: 0.8615\n",
      "Epoch 4/500\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5539 - accuracy: 0.8880 - val_loss: 0.5738 - val_accuracy: 0.8345\n",
      "Epoch 5/500\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5510 - accuracy: 0.8952 - val_loss: 0.5764 - val_accuracy: 0.8352\n",
      "Epoch 6/500\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 180s - loss: 0.5489 - accuracy: 0.8986 - val_loss: 0.5705 - val_accuracy: 0.8615\n",
      "Epoch 7/500\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5475 - accuracy: 0.9025 - val_loss: 0.5701 - val_accuracy: 0.8565\n",
      "Epoch 8/500\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5460 - accuracy: 0.9053 - val_loss: 0.5782 - val_accuracy: 0.8231\n",
      "Epoch 9/500\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5450 - accuracy: 0.9078 - val_loss: 0.5695 - val_accuracy: 0.8623\n",
      "Epoch 10/500\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5438 - accuracy: 0.9100 - val_loss: 0.5699 - val_accuracy: 0.8581\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5426 - accuracy: 0.9134 - val_loss: 0.5693 - val_accuracy: 0.8535\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 180s - loss: 0.5408 - accuracy: 0.9167 - val_loss: 0.5692 - val_accuracy: 0.8623\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.86301\n",
      "42036/42036 - 181s - loss: 0.5405 - accuracy: 0.9181 - val_loss: 0.5715 - val_accuracy: 0.8527\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 250, 16)           160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_20  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,449\n",
      "Trainable params: 160,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7882/7882 [==============================] - 18s 2ms/step - loss: 0.5732 - accuracy: 0.8516\n",
      "0.5732001662254333 0.8515605330467224\n"
     ]
    }
   ],
   "source": [
    "# approach3\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model_3_sentiment_dnn.h5\", save_best_only=True)\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'model_3_sentiment_dnn.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "batch_size=1\n",
    "num_epochs = 500\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_3.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model_3.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "#save the model\n",
    "model_3.save(\"%s/model_3_sentiment_dnn.h5\" %model_file)\n",
    "print(model_3.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model_3.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42036/42036 - 180s - loss: 0.5886 - binary_accuracy: 0.5018 - val_loss: 0.5688 - val_binary_accuracy: 0.5019\n",
      "Epoch 2/50\n",
      "42036/42036 - 181s - loss: 0.5619 - binary_accuracy: 0.5018 - val_loss: 0.5790 - val_binary_accuracy: 0.5019\n",
      "Epoch 3/50\n",
      "42036/42036 - 181s - loss: 0.5576 - binary_accuracy: 0.5035 - val_loss: 0.5761 - val_binary_accuracy: 0.5030\n",
      "Epoch 4/50\n",
      "42036/42036 - 180s - loss: 0.5548 - binary_accuracy: 0.5065 - val_loss: 0.5714 - val_binary_accuracy: 0.5084\n",
      "Epoch 5/50\n",
      "42036/42036 - 181s - loss: 0.5522 - binary_accuracy: 0.5124 - val_loss: 0.5716 - val_binary_accuracy: 0.5148\n",
      "Epoch 6/50\n",
      "42036/42036 - 180s - loss: 0.5499 - binary_accuracy: 0.5171 - val_loss: 0.5723 - val_binary_accuracy: 0.5194\n",
      "Epoch 7/50\n",
      "42036/42036 - 180s - loss: 0.5487 - binary_accuracy: 0.5222 - val_loss: 0.5743 - val_binary_accuracy: 0.5213\n",
      "Epoch 8/50\n",
      "42036/42036 - 180s - loss: 0.5472 - binary_accuracy: 0.5224 - val_loss: 0.5670 - val_binary_accuracy: 0.5240\n",
      "Epoch 9/50\n",
      "42036/42036 - 180s - loss: 0.5452 - binary_accuracy: 0.5273 - val_loss: 0.5696 - val_binary_accuracy: 0.5205\n",
      "Epoch 10/50\n",
      "42036/42036 - 180s - loss: 0.5434 - binary_accuracy: 0.5317 - val_loss: 0.5717 - val_binary_accuracy: 0.5365\n",
      "Epoch 11/50\n",
      "42036/42036 - 180s - loss: 0.5425 - binary_accuracy: 0.5361 - val_loss: 0.5685 - val_binary_accuracy: 0.5392\n",
      "Epoch 12/50\n",
      "42036/42036 - 181s - loss: 0.5419 - binary_accuracy: 0.5426 - val_loss: 0.5688 - val_binary_accuracy: 0.5407\n",
      "Epoch 13/50\n",
      "42036/42036 - 185s - loss: 0.5404 - binary_accuracy: 0.5438 - val_loss: 0.5678 - val_binary_accuracy: 0.5422\n",
      "Epoch 14/50\n",
      "42036/42036 - 179s - loss: 0.5399 - binary_accuracy: 0.5517 - val_loss: 0.5678 - val_binary_accuracy: 0.5620\n",
      "Epoch 15/50\n",
      "42036/42036 - 180s - loss: 0.5391 - binary_accuracy: 0.5585 - val_loss: 0.5686 - val_binary_accuracy: 0.5666\n",
      "Epoch 16/50\n",
      "42036/42036 - 180s - loss: 0.5390 - binary_accuracy: 0.5629 - val_loss: 0.5715 - val_binary_accuracy: 0.5616\n",
      "Epoch 17/50\n",
      "42036/42036 - 179s - loss: 0.5377 - binary_accuracy: 0.5645 - val_loss: 0.5801 - val_binary_accuracy: 0.5654\n",
      "Epoch 18/50\n",
      "42036/42036 - 180s - loss: 0.5374 - binary_accuracy: 0.5679 - val_loss: 0.5720 - val_binary_accuracy: 0.5719\n",
      "Epoch 19/50\n",
      "42036/42036 - 180s - loss: 0.5367 - binary_accuracy: 0.5701 - val_loss: 0.5694 - val_binary_accuracy: 0.5731\n",
      "Epoch 20/50\n",
      "42036/42036 - 179s - loss: 0.5364 - binary_accuracy: 0.5765 - val_loss: 0.5736 - val_binary_accuracy: 0.5837\n",
      "Epoch 21/50\n",
      "42036/42036 - 180s - loss: 0.5366 - binary_accuracy: 0.5766 - val_loss: 0.5691 - val_binary_accuracy: 0.5776\n",
      "Epoch 22/50\n",
      "42036/42036 - 179s - loss: 0.5358 - binary_accuracy: 0.5788 - val_loss: 0.5710 - val_binary_accuracy: 0.5887\n",
      "Epoch 23/50\n",
      "42036/42036 - 179s - loss: 0.5358 - binary_accuracy: 0.5849 - val_loss: 0.5691 - val_binary_accuracy: 0.5997\n",
      "Epoch 24/50\n",
      "42036/42036 - 180s - loss: 0.5355 - binary_accuracy: 0.5871 - val_loss: 0.5700 - val_binary_accuracy: 0.5833\n",
      "Epoch 25/50\n",
      "42036/42036 - 179s - loss: 0.5351 - binary_accuracy: 0.5892 - val_loss: 0.5688 - val_binary_accuracy: 0.5902\n",
      "Epoch 26/50\n",
      "42036/42036 - 179s - loss: 0.5350 - binary_accuracy: 0.5899 - val_loss: 0.5714 - val_binary_accuracy: 0.6104\n",
      "Epoch 27/50\n",
      "42036/42036 - 179s - loss: 0.5348 - binary_accuracy: 0.5963 - val_loss: 0.5696 - val_binary_accuracy: 0.5978\n",
      "Epoch 28/50\n",
      "42036/42036 - 180s - loss: 0.5345 - binary_accuracy: 0.6052 - val_loss: 0.5694 - val_binary_accuracy: 0.5917\n",
      "Epoch 29/50\n",
      "42036/42036 - 180s - loss: 0.5341 - binary_accuracy: 0.6074 - val_loss: 0.5722 - val_binary_accuracy: 0.5928\n",
      "Epoch 30/50\n",
      "42036/42036 - 179s - loss: 0.5343 - binary_accuracy: 0.6124 - val_loss: 0.5704 - val_binary_accuracy: 0.6054\n",
      "Epoch 31/50\n",
      "42036/42036 - 180s - loss: 0.5337 - binary_accuracy: 0.6194 - val_loss: 0.5738 - val_binary_accuracy: 0.6149\n",
      "Epoch 32/50\n",
      "42036/42036 - 179s - loss: 0.5336 - binary_accuracy: 0.6219 - val_loss: 0.5676 - val_binary_accuracy: 0.6294\n",
      "Epoch 33/50\n",
      "42036/42036 - 179s - loss: 0.5334 - binary_accuracy: 0.6160 - val_loss: 0.5697 - val_binary_accuracy: 0.6020\n",
      "Epoch 34/50\n",
      "42036/42036 - 180s - loss: 0.5325 - binary_accuracy: 0.6283 - val_loss: 0.5678 - val_binary_accuracy: 0.6279\n",
      "Epoch 35/50\n",
      "42036/42036 - 179s - loss: 0.5324 - binary_accuracy: 0.6410 - val_loss: 0.5720 - val_binary_accuracy: 0.6339\n",
      "Epoch 36/50\n",
      "42036/42036 - 180s - loss: 0.5325 - binary_accuracy: 0.6528 - val_loss: 0.5731 - val_binary_accuracy: 0.6815\n",
      "Epoch 37/50\n",
      "42036/42036 - 180s - loss: 0.5328 - binary_accuracy: 0.6652 - val_loss: 0.5702 - val_binary_accuracy: 0.6743\n",
      "Epoch 38/50\n",
      "42036/42036 - 179s - loss: 0.5326 - binary_accuracy: 0.6740 - val_loss: 0.5736 - val_binary_accuracy: 0.6655\n",
      "Epoch 39/50\n",
      "42036/42036 - 190s - loss: 0.5324 - binary_accuracy: 0.6877 - val_loss: 0.5706 - val_binary_accuracy: 0.6884\n",
      "Epoch 40/50\n",
      "42036/42036 - 181s - loss: 0.5321 - binary_accuracy: 0.6906 - val_loss: 0.5689 - val_binary_accuracy: 0.7005\n",
      "Epoch 41/50\n",
      "42036/42036 - 180s - loss: 0.5316 - binary_accuracy: 0.6989 - val_loss: 0.5692 - val_binary_accuracy: 0.7002\n",
      "Epoch 42/50\n",
      "42036/42036 - 180s - loss: 0.5319 - binary_accuracy: 0.7053 - val_loss: 0.5677 - val_binary_accuracy: 0.6998\n",
      "Epoch 43/50\n",
      "42036/42036 - 180s - loss: 0.5315 - binary_accuracy: 0.7151 - val_loss: 0.5686 - val_binary_accuracy: 0.7135\n",
      "Epoch 44/50\n",
      "42036/42036 - 180s - loss: 0.5317 - binary_accuracy: 0.7175 - val_loss: 0.5706 - val_binary_accuracy: 0.7264\n",
      "Epoch 45/50\n",
      "42036/42036 - 180s - loss: 0.5317 - binary_accuracy: 0.7232 - val_loss: 0.5810 - val_binary_accuracy: 0.7085\n",
      "Epoch 46/50\n",
      "42036/42036 - 179s - loss: 0.5311 - binary_accuracy: 0.7330 - val_loss: 0.5684 - val_binary_accuracy: 0.7409\n",
      "Epoch 47/50\n",
      "42036/42036 - 180s - loss: 0.5316 - binary_accuracy: 0.7373 - val_loss: 0.5740 - val_binary_accuracy: 0.7275\n",
      "Epoch 48/50\n",
      "42036/42036 - 180s - loss: 0.5313 - binary_accuracy: 0.7488 - val_loss: 0.5710 - val_binary_accuracy: 0.7489\n",
      "Epoch 49/50\n",
      "42036/42036 - 180s - loss: 0.5309 - binary_accuracy: 0.7578 - val_loss: 0.5717 - val_binary_accuracy: 0.7903\n",
      "Epoch 50/50\n",
      "42036/42036 - 180s - loss: 0.5304 - binary_accuracy: 0.7692 - val_loss: 0.5699 - val_binary_accuracy: 0.7705\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 250, 16)           160016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_21  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,449\n",
      "Trainable params: 160,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7882/7882 [==============================] - 18s 2ms/step - loss: 0.5716 - binary_accuracy: 0.7626\n",
      "0.5716314911842346 0.7626237273216248\n"
     ]
    }
   ],
   "source": [
    "# approach4\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model_4_sentiment_dnn.h5\", save_best_only=True)\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'model_4_sentiment_dnn.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "batch_size=1\n",
    "num_epochs = 50\n",
    "model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_4.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), optimizer='adam', metrics=tf.metrics.BinaryAccuracy(threshold=0.0))\n",
    "\n",
    "history = model_4.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=2)\n",
    "#save the model\n",
    "model_4.save(\"%s/model_4_sentiment_dnn.h5\" %model_file)\n",
    "print(model_4.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model_4.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84399, saving model to /tf/deep_learning/sentiment_analysis/lib/modelmodel_5_best.h5\n",
      "42036/42036 - 188s - loss: 0.5911 - accuracy: 0.8025 - val_loss: 0.5764 - val_accuracy: 0.8440\n",
      "Epoch 2/500\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.84399\n",
      "42036/42036 - 189s - loss: 0.5727 - accuracy: 0.8444 - val_loss: 0.5955 - val_accuracy: 0.8124\n",
      "Epoch 3/500\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.84399\n",
      "42036/42036 - 189s - loss: 0.5716 - accuracy: 0.8485 - val_loss: 0.5885 - val_accuracy: 0.8086\n",
      "Epoch 4/500\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84399 to 0.84513, saving model to /tf/deep_learning/sentiment_analysis/lib/modelmodel_5_best.h5\n",
      "42036/42036 - 188s - loss: 0.5684 - accuracy: 0.8560 - val_loss: 0.5889 - val_accuracy: 0.8451\n",
      "Epoch 5/500\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 188s - loss: 0.5684 - accuracy: 0.8578 - val_loss: 0.5729 - val_accuracy: 0.8444\n",
      "Epoch 6/500\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 188s - loss: 0.5667 - accuracy: 0.8616 - val_loss: 0.5768 - val_accuracy: 0.8318\n",
      "Epoch 7/500\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 189s - loss: 0.5664 - accuracy: 0.8613 - val_loss: 0.5797 - val_accuracy: 0.8451\n",
      "Epoch 8/500\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 188s - loss: 0.5668 - accuracy: 0.8630 - val_loss: 0.5792 - val_accuracy: 0.8345\n",
      "Epoch 9/500\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 188s - loss: 0.5666 - accuracy: 0.8606 - val_loss: 0.5951 - val_accuracy: 0.7702\n",
      "Epoch 10/500\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 188s - loss: 0.5671 - accuracy: 0.8595 - val_loss: 0.6029 - val_accuracy: 0.8196\n",
      "Epoch 11/500\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 189s - loss: 0.5687 - accuracy: 0.8588 - val_loss: 0.6025 - val_accuracy: 0.8215\n",
      "Epoch 12/500\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84513\n",
      "42036/42036 - 188s - loss: 0.5659 - accuracy: 0.8657 - val_loss: 0.5823 - val_accuracy: 0.8444\n",
      "Epoch 13/500\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.84513 to 0.84589, saving model to /tf/deep_learning/sentiment_analysis/lib/modelmodel_5_best.h5\n",
      "42036/42036 - 189s - loss: 0.5661 - accuracy: 0.8620 - val_loss: 0.5772 - val_accuracy: 0.8459\n",
      "Epoch 14/500\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84589\n",
      "42036/42036 - 189s - loss: 0.5686 - accuracy: 0.8588 - val_loss: 0.5865 - val_accuracy: 0.8124\n",
      "Epoch 15/500\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84589\n",
      "42036/42036 - 188s - loss: 0.5643 - accuracy: 0.8675 - val_loss: 0.5775 - val_accuracy: 0.8368\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_17  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2400)              40800     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 2401      \n",
      "=================================================================\n",
      "Total params: 203,201\n",
      "Trainable params: 203,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7882/7882 [==============================] - 18s 2ms/step - loss: 0.5765 - accuracy: 0.8420\n",
      "0.5764822959899902 0.8420451879501343\n"
     ]
    }
   ],
   "source": [
    "# approach 5\n",
    "# creating simple model\n",
    "# callback for best model\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model_5_best.h5\", save_best_only=True)\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'model_5_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "batch_size=1\n",
    "num_epochs = 500\n",
    "model_5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(2400, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.50),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_5.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model_5.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "# history = model_5.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[checkpoint_cb], verbose=2)\n",
    "# rollback to the best model\n",
    "model_5 = tf.keras.models.load_model(\"model_5_best.h5\")\n",
    "#save the model\n",
    "model_5.save(\"%s/model_5_sentiment_dnn.h5\" %model_file)\n",
    "print(model_5.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model_5.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "42036/42036 - 183s - loss: 0.5892 - accuracy: 0.8071 - val_loss: 0.5693 - val_accuracy: 0.8508\n",
      "Epoch 2/500\n",
      "42036/42036 - 183s - loss: 0.5616 - accuracy: 0.8713 - val_loss: 0.5696 - val_accuracy: 0.8474\n",
      "Epoch 3/500\n",
      "42036/42036 - 182s - loss: 0.5570 - accuracy: 0.8815 - val_loss: 0.5697 - val_accuracy: 0.8482\n",
      "Epoch 4/500\n",
      "42036/42036 - 182s - loss: 0.5538 - accuracy: 0.8881 - val_loss: 0.5715 - val_accuracy: 0.8444\n",
      "Epoch 5/500\n",
      "42036/42036 - 182s - loss: 0.5519 - accuracy: 0.8918 - val_loss: 0.5722 - val_accuracy: 0.8512\n",
      "Epoch 6/500\n",
      "42036/42036 - 182s - loss: 0.5501 - accuracy: 0.8962 - val_loss: 0.5709 - val_accuracy: 0.8630\n",
      "Epoch 7/500\n",
      "42036/42036 - 182s - loss: 0.5484 - accuracy: 0.9004 - val_loss: 0.5741 - val_accuracy: 0.8402\n",
      "Epoch 8/500\n",
      "42036/42036 - 182s - loss: 0.5461 - accuracy: 0.9057 - val_loss: 0.5743 - val_accuracy: 0.8402\n",
      "Epoch 9/500\n",
      "42036/42036 - 182s - loss: 0.5449 - accuracy: 0.9076 - val_loss: 0.5724 - val_accuracy: 0.8588\n",
      "Epoch 10/500\n",
      "42036/42036 - 182s - loss: 0.5439 - accuracy: 0.9098 - val_loss: 0.5711 - val_accuracy: 0.8607\n",
      "Epoch 11/500\n",
      "42036/42036 - 182s - loss: 0.5421 - accuracy: 0.9135 - val_loss: 0.5723 - val_accuracy: 0.8505\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_23  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 25        \n",
      "=================================================================\n",
      "Total params: 160,433\n",
      "Trainable params: 160,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7882/7882 [==============================] - 18s 2ms/step - loss: 0.5683 - accuracy: 0.8579\n",
      "0.5682713389396667 0.8579040765762329\n"
     ]
    }
   ],
   "source": [
    "# approach 6\n",
    "# creating simple model\n",
    "# callback for best model\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model_6_best.h5\", save_best_only=True)\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'model_6_best.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model_6_best.h5\", save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "batch_size=1\n",
    "num_epochs = 500\n",
    "model_6 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "#     tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_6.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "# history = model_5.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "# history = model_6.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[checkpoint_cb], verbose=2)\n",
    "history = model_6.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[checkpoint_cb, early_stopping_cb], verbose=2)\n",
    "# rollback to the best model\n",
    "# model_6 = tf.keras.models.load_model(\"model_6_best.h5\")\n",
    "#save the model\n",
    "model_6.save(\"%s/model_6_sentiment_dnn.h5\" %model_file)\n",
    "print(model_6.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model_6.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.86720, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_multi_dnn.h5\n",
      "42036/42036 - 196s - loss: 0.3508 - accuracy: 0.8396 - val_loss: 0.3151 - val_accuracy: 0.8672\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.86720 to 0.87139, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_multi_dnn.h5\n",
      "42036/42036 - 190s - loss: 0.2628 - accuracy: 0.8904 - val_loss: 0.2945 - val_accuracy: 0.8714\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.87139\n",
      "42036/42036 - 211s - loss: 0.2359 - accuracy: 0.9022 - val_loss: 0.3990 - val_accuracy: 0.8508\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.87139\n",
      "42036/42036 - 233s - loss: 0.2216 - accuracy: 0.9102 - val_loss: 0.3236 - val_accuracy: 0.8691\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87139\n",
      "42036/42036 - 235s - loss: 0.2095 - accuracy: 0.9162 - val_loss: 0.3231 - val_accuracy: 0.8702\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.87139 to 0.87215, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_multi_dnn.h5\n",
      "42036/42036 - 251s - loss: 0.2001 - accuracy: 0.9196 - val_loss: 0.3485 - val_accuracy: 0.8721\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.87215\n",
      "42036/42036 - 218s - loss: 0.1907 - accuracy: 0.9240 - val_loss: 0.3454 - val_accuracy: 0.8718\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.87215\n",
      "42036/42036 - 210s - loss: 0.1788 - accuracy: 0.9298 - val_loss: 0.3694 - val_accuracy: 0.8683\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87215\n",
      "42036/42036 - 236s - loss: 0.1665 - accuracy: 0.9374 - val_loss: 0.3734 - val_accuracy: 0.8661\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87215\n",
      "42036/42036 - 236s - loss: 0.1567 - accuracy: 0.9408 - val_loss: 0.3789 - val_accuracy: 0.8676\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87215\n",
      "42036/42036 - 223s - loss: 0.1446 - accuracy: 0.9472 - val_loss: 0.4320 - val_accuracy: 0.8714\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87215\n",
      "42036/42036 - 227s - loss: 0.1346 - accuracy: 0.9506 - val_loss: 0.4969 - val_accuracy: 0.8577\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_25  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 24)                408       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 64)                1600      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 162,073\n",
      "Trainable params: 162,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7882/7882 [==============================] - 34s 4ms/step - loss: 0.4973 - accuracy: 0.8560\n",
      "0.49731770157814026 0.8560010194778442\n"
     ]
    }
   ],
   "source": [
    "# creating model with multiple dense layer\n",
    "batch_size=1\n",
    "num_epochs = 50\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"sentiment_multi_dnn.h5\", save_best_only=True)\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'sentiment_multi_dnn.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "# history = model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=2)\n",
    "#save the model\n",
    "model.save(\"%s/sentiment_multi_dnn.h5\" %model_file)\n",
    "print(model.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81925, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_multi_dnn_v2.h5\n",
      "42036/42036 - 281s - loss: 0.3672 - accuracy: 0.8382 - val_loss: 0.4021 - val_accuracy: 0.8193\n",
      "Epoch 2/50\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.81925 to 0.87405, saving model to /tf/deep_learning/sentiment_analysis/lib/modelsentiment_multi_dnn_v2.h5\n",
      "42036/42036 - 261s - loss: 0.2811 - accuracy: 0.8873 - val_loss: 0.3249 - val_accuracy: 0.8740\n",
      "Epoch 3/50\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 247s - loss: 0.2575 - accuracy: 0.8988 - val_loss: 0.3398 - val_accuracy: 0.8699\n",
      "Epoch 4/50\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 243s - loss: 0.2435 - accuracy: 0.9071 - val_loss: 0.3389 - val_accuracy: 0.8691\n",
      "Epoch 5/50\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 251s - loss: 0.2373 - accuracy: 0.9108 - val_loss: 0.3435 - val_accuracy: 0.8626\n",
      "Epoch 6/50\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 244s - loss: 0.2249 - accuracy: 0.9160 - val_loss: 0.3749 - val_accuracy: 0.8592\n",
      "Epoch 7/50\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 236s - loss: 0.2184 - accuracy: 0.9207 - val_loss: 0.4219 - val_accuracy: 0.8664\n",
      "Epoch 8/50\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 248s - loss: 0.2064 - accuracy: 0.9245 - val_loss: 0.4112 - val_accuracy: 0.8695\n",
      "Epoch 9/50\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 238s - loss: 0.1998 - accuracy: 0.9288 - val_loss: 0.4454 - val_accuracy: 0.8680\n",
      "Epoch 10/50\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 251s - loss: 0.1862 - accuracy: 0.9336 - val_loss: 0.4129 - val_accuracy: 0.8695\n",
      "Epoch 11/50\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 231s - loss: 0.1804 - accuracy: 0.9372 - val_loss: 0.6504 - val_accuracy: 0.8634\n",
      "Epoch 12/50\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.87405\n",
      "42036/42036 - 209s - loss: 0.1694 - accuracy: 0.9421 - val_loss: 0.5837 - val_accuracy: 0.8623\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 250, 16)           160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_26  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 261,121\n",
      "Trainable params: 261,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7882/7882 [==============================] - 23s 3ms/step - loss: 0.5853 - accuracy: 0.8609\n",
      "0.5853143334388733 0.8609489798545837\n"
     ]
    }
   ],
   "source": [
    "# creating model V2\n",
    "batch_size=1\n",
    "num_epochs = 50\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"sentiment_multi_dnn_v2.h5\", save_best_only=True)\n",
    "saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'sentiment_multi_dnn_v2.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto', save_weights_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.50),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping], verbose=2)\n",
    "# history = model.fit(training_padded, training_labels, batch_size=batch_size, epochs=num_epochs, validation_data=(validation_padded, validation_labels), verbose=2)\n",
    "#save the model\n",
    "model.save(\"%s/sentiment_multi_dnn_v2.h5\" %model_file)\n",
    "print(model.summary())\n",
    "\n",
    "# Final evaluation of the model\n",
    "score, acc = model.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating LSTM model\n",
    "# lstm_model = tf.keras.Sequential()\n",
    "# lstm_model.add(tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_review_length, trainable=False))\n",
    "# lstm_model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "# lstm_model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "# lstm_model.add(tf.keras.layers.Dropout(0.50))\n",
    "# lstm_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "# # try using different optimizers and different optimizer configs\n",
    "# lstm_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the best LSTM model and early stopping\n",
    "# saveBestModel = tf.keras.callbacks.ModelCheckpoint(model_file+'sentiment_lstm_best.h5', monitor='accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)\n",
    "# earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=1\n",
    "# # Fit the model\n",
    "# lstm_model.fit(training_padded, training_labels, batch_size=batch_size, epochs=50,validation_data=(validation_padded, validation_labels), callbacks=[saveBestModel, earlyStopping])\n",
    "# # Final evaluation of the model\n",
    "# score, acc = lstm_model.evaluate(testing_padded, testing_labels, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save the model\n",
    "# lstm_model.save(\"%s/sentiment_lstm.h5\" %model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in his.history:\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Final evaluation of the lstm model\n",
    "# batch_size=1\n",
    "# score, acc = lstm_model.evaluate(testing_padded, testing_labels, batch_size=batch_size)\n",
    "# print(score, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
